{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def0622f-e283-4d3d-bcdd-eda6971d8d91",
      "metadata": {
        "id": "def0622f-e283-4d3d-bcdd-eda6971d8d91",
        "outputId": "e6e9824b-bed8-41c9-c28a-1db7c7b7db42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Jupyter notebook. Loading juliacall extension. Set `PYSR_AUTOLOAD_EXTENSIONS=no` to disable.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-auth\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive\n",
        "import os\n",
        "\n",
        "path = '/content/drive/My Drive'\n",
        "\n",
        "if os.path.isdir(path):\n",
        "    contents = os.listdir(path)\n",
        "    print(f\"Contents of {path}:\")\n",
        "    for item in contents:\n",
        "        print(item)\n",
        "\n",
        "files = os.listdir('/content/drive/My Drive/bcg_dataset')\n",
        "files = os.listdir('/content/drive/My Drive/SP_BCG')\n",
        "files = os.listdir('/content/drive/My Drive/DP_BCG')\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiNIZHSqN3QD",
        "outputId": "27a4f2b1-f3f7-4dd4-ca35-114aed3680c8"
      },
      "id": "AiNIZHSqN3QD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
            "Mounted at /content/drive\n",
            " all_feature_importances_SP.csv\t\t\t     predictions_fold_0.csv\n",
            " average_model_performance_results_DP_Original.csv   predictions_fold_1.csv\n",
            " average_model_performance_results_Original.csv      predictions_fold_2.csv\n",
            " average_model_performance_results_SP_SR.csv\t     predictions_fold_3.csv\n",
            " bcg_dataset\t\t\t\t\t     predictions_fold_4.csv\n",
            "'Colab Notebooks'\t\t\t\t     results_original_SP.csv\n",
            " DP_BCG\t\t\t\t\t\t     results_selected_SP.csv\n",
            " model_performance_results_DP_Original.csv\t     selected_feature_importances_SP.csv\n",
            " model_performance_results_SP_Original.csv\t     SP_BCG\n",
            " model_performance_results_SR_SP.csv\n",
            "Contents of /content/drive/My Drive:\n",
            "bcg_dataset\n",
            "Colab Notebooks\n",
            "average_model_performance_results_SP_SR.csv\n",
            "model_performance_results_SR_SP.csv\n",
            "model_performance_results_SP_Original.csv\n",
            "average_model_performance_results_Original.csv\n",
            "predictions_fold_0.csv\n",
            "predictions_fold_1.csv\n",
            "predictions_fold_2.csv\n",
            "predictions_fold_3.csv\n",
            "predictions_fold_4.csv\n",
            "model_performance_results_DP_Original.csv\n",
            "average_model_performance_results_DP_Original.csv\n",
            "SP_BCG\n",
            "DP_BCG\n",
            "all_feature_importances_SP.csv\n",
            "selected_feature_importances_SP.csv\n",
            "results_original_SP.csv\n",
            "results_selected_SP.csv\n",
            "['DP_original_predictions_fold_0.csv', 'DP_original_predictions_fold_1.csv', 'DP_original_predictions_fold_2.csv', 'DP_original_predictions_fold_3.csv', 'DP_original_predictions_fold_4.csv', 'model_performance_results_DP_Original.csv', 'average_model_performance_results_DP_Original.csv', 'feat_fold_0_selected_DP.csv', 'feat_fold_2_selected_DP.csv', 'feat_fold_1_selected_DP.csv', 'feat_fold_3_selected_DP.csv', 'feat_fold_4_selected_DP.csv', 'results_selected_DP.csv', 'results_original_DP.csv', 'average_results_per_model_original_DP.csv', 'average_results_per_model_selected_DP.csv', 'feature_categories_DP.csv', 'SELECTED_feature_categories_DP.csv', 'DP_selected_predictions_fold_0.csv', 'DP_selected_predictions_fold_1.csv', 'DP_selected_predictions_fold_2.csv', 'DP_selected_predictions_fold_3.csv', 'DP_selected_predictions_fold_4.csv', 'model_performance_results_SR_DP_Selected.csv', 'selected_feature_importances_DP.csv', 'all_feature_importances_DP.csv', 'average_model_performance_results_DP_SR_Selected.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysr\n",
        "import pandas as pd\n",
        "import pysr\n",
        "from pysr import PySRRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1u5NGweN2F2",
        "outputId": "81fc6d04-849f-4115-dc80-a6b6f7234f6c"
      },
      "id": "w1u5NGweN2F2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysr\n",
            "  Downloading pysr-0.18.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m734.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.12)\n",
            "Requirement already satisfied: pandas<3.0.0,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (2.0.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (1.2.2)\n",
            "Collecting juliacall==0.9.19 (from pysr)\n",
            "  Downloading juliacall-0.9.19-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (8.1.7)\n",
            "Requirement already satisfied: setuptools>=50.0.0 in /usr/local/lib/python3.10/dist-packages (from pysr) (67.7.2)\n",
            "Collecting juliapkg~=0.1.8 (from juliacall==0.9.19->pysr)\n",
            "  Downloading juliapkg-0.1.11-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=0.21.0->pysr) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->pysr) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->pysr) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->pysr) (3.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy<2.0.0,>=1.0.0->pysr) (1.3.0)\n",
            "Collecting semantic-version~=2.9 (from juliapkg~=0.1.8->juliacall==0.9.19->pysr)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=0.21.0->pysr) (1.16.0)\n",
            "Installing collected packages: semantic-version, juliapkg, juliacall, pysr\n",
            "Successfully installed juliacall-0.9.19 juliapkg-0.1.11 pysr-0.18.2 semantic-version-2.10.0\n",
            "[juliapkg] Locating Julia ~1.6.7, ~1.7, ~1.8, ~1.9, =1.10.0\n",
            "[juliapkg] Querying Julia versions from https://julialang-s3.julialang.org/bin/versions.json\n",
            "[juliapkg] WARNING: About to install Julia 1.10.0 to /root/.julia/environments/pyjuliapkg/pyjuliapkg/install.\n",
            "[juliapkg]   If you use juliapkg in more than one environment, you are likely to have Julia\n",
            "[juliapkg]   installed in multiple locations. It is recommended to install JuliaUp\n",
            "[juliapkg]   (https://github.com/JuliaLang/juliaup) or Julia (https://julialang.org/downloads)\n",
            "[juliapkg]   yourself.\n",
            "[juliapkg] Downloading Julia from https://julialang-s3.julialang.org/bin/linux/x64/1.10/julia-1.10.0-linux-x86_64.tar.gz\n",
            "             download complete\n",
            "[juliapkg] Verifying download\n",
            "[juliapkg] Installing Julia 1.10.0 to /root/.julia/environments/pyjuliapkg/pyjuliapkg/install\n",
            "[juliapkg] Using Julia 1.10.0 at /root/.julia/environments/pyjuliapkg/pyjuliapkg/install/bin/julia\n",
            "[juliapkg] Using Julia project at /root/.julia/environments/pyjuliapkg\n",
            "[juliapkg] Installing packages:\n",
            "           julia> import Pkg\n",
            "           julia> Pkg.Registry.update()\n",
            "           julia> Pkg.add([Pkg.PackageSpec(name=\"PythonCall\", uuid=\"6099a3de-0909-46bc-b1f4-468b9a2dfc0d\"), Pkg.PackageSpec(name=\"SymbolicRegression\", uuid=\"8254be44-1295-4e6a-a16d-46603ac705cb\"), Pkg.PackageSpec(name=\"Serialization\", uuid=\"9e88b42a-f829-5b0c-bbe9-9e923198166b\")])\n",
            "           julia> Pkg.resolve()\n",
            "           julia> Pkg.precompile()\n",
            "Detected Jupyter notebook. Loading juliacall extension. Set `PYSR_AUTOLOAD_EXTENSIONS=no` to disable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de4ff397-6e3c-4a2f-b397-1321bc4b36a9",
      "metadata": {
        "id": "de4ff397-6e3c-4a2f-b397-1321bc4b36a9"
      },
      "outputs": [],
      "source": [
        "def load_datasets():\n",
        "    fold_files = [\n",
        "    '/content/drive/My Drive/bcg_dataset/feat_fold_0.csv',\n",
        "        '/content/drive/My Drive/bcg_dataset/feat_fold_1.csv',\n",
        "        '/content/drive/My Drive/bcg_dataset/feat_fold_2.csv',\n",
        "        '/content/drive/My Drive/bcg_dataset/feat_fold_3.csv',\n",
        "        '/content/drive/My Drive/bcg_dataset/feat_fold_4.csv'\n",
        "    ]\n",
        "    return [pd.read_csv(f) for f in fold_files]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37776189-a11c-4152-b449-21c3246cad29",
      "metadata": {
        "id": "37776189-a11c-4152-b449-21c3246cad29"
      },
      "outputs": [],
      "source": [
        "def split_datasets(folds):\n",
        "    num_folds = len(folds)\n",
        "    splits = []\n",
        "    for r in range( num_folds):  # From 1 to 4 folds for training\n",
        "        train_indices = list(range(num_folds))\n",
        "\n",
        "        train_indices.remove(r)\n",
        "        test_indices = [r]\n",
        "        train_dfs = [folds[i] for i in train_indices]\n",
        "        test_dfs = [folds[i] for i in test_indices]\n",
        "        splits.append((pd.concat(train_dfs), pd.concat(test_dfs)))\n",
        "    return splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53a5033-7bfa-46ae-b19d-2fe2db218f25",
      "metadata": {
        "id": "f53a5033-7bfa-46ae-b19d-2fe2db218f25"
      },
      "outputs": [],
      "source": [
        "pysr_settings = {\n",
        "'niterations':100,\n",
        "    'timeout_in_seconds':60 * 60 * 24,\n",
        "    'early_stop_condition':(\n",
        "        \"stop_if(loss, complexity) = loss < 1e-6 && complexity < 10\"\n",
        "        # Stop early if we find a good and simple equation\n",
        "    ),\n",
        "    'ncycles_per_iteration':200,\n",
        "    'binary_operators':[\"+\", \"*\", \"/\", \"-\"],\n",
        "    'unary_operators':[\"sin\", \"cos\", \"exp\", \"log\", \"abs\", \"sqrt\", \"inv\"],\n",
        "    'extra_sympy_mappings':{'inv': lambda x: 1/x},\n",
        "    #'populations':50,\n",
        "    #'population_size':1000,\n",
        "    #'max_evals':5000,\n",
        "    #'maxdepth':10,\n",
        "    #'maxsize':1000,\n",
        "    'progress':True,\n",
        "    #'precision':64,\n",
        "    #'weight_randomize':0.1,\n",
        "    #'cluster_manager':None,\n",
        "    #'parsimony':0.001,\n",
        "    #'procs':4,  # Set to 0 to turn off parallelism for determinism\n",
        "    'model_selection':\"best\",\n",
        "    'verbosity':0,\n",
        "    #'select_k_features':29,\n",
        "    #'select_k_features':20,\n",
        "    #'complexity_of_constants':2,\n",
        "    #'elementwise_loss':\"L1DistLoss()\",\n",
        "    # random_state=42,  # Set a fixed seed for reproducibility\n",
        "    #deterministic=True,  # Ensure deterministic behavior\n",
        "    'warm_start':False,  # Start fresh for this example; set to True to continue from last .fit() call\n",
        "    #'bumper':True,\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f46779d-e9a3-4bfb-bf52-0599c65c0fef",
      "metadata": {
        "id": "8f46779d-e9a3-4bfb-bf52-0599c65c0fef"
      },
      "outputs": [],
      "source": [
        "def perform_symbolic_regression(splits, pysr_settings, number_of_features = 10):\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, (train_data, test_data) in enumerate(splits):\n",
        "        # Prepare the datasets, excluding 'patient' and 'trial' columns for X\n",
        "        X_train = train_data.drop(['SP', 'DP', 'trial', 'patient'], axis=1)\n",
        "        y_train = train_data[['SP', 'DP']]\n",
        "        X_test = test_data.drop(['SP', 'DP', 'trial', 'patient'], axis=1)\n",
        "        y_test = test_data[['SP', 'DP']]\n",
        "\n",
        "        for target, y_tr, y_te in zip(['SP', 'DP'], [y_train.iloc[:, 0], y_train.iloc[:, 1]], [y_test.iloc[:, 0], y_test.iloc[:, 1]]):\n",
        "\n",
        "            estimator = LinearRegression() #RandomForestRegressor()#\n",
        "            rfe = RFE(estimator=estimator,n_features_to_select=number_of_features, step=1)\n",
        "            rfe.fit(X_train, y_tr)\n",
        "\n",
        "            best_features = rfe.feature_names_in_[rfe.ranking_[0:number_of_features]]\n",
        "            #print(best_features)\n",
        "\n",
        "            model = PySRRegressor(**pysr_settings)\n",
        "            model.fit(X_train[best_features], y_tr)\n",
        "\n",
        "            predictions = model.predict(X_test[best_features])\n",
        "            score = r2_score(y_te, predictions)\n",
        "            mse = mean_squared_error(y_te, predictions)\n",
        "            mse_naive = mean_squared_error(y_te, [np.mean(y_te)]*len(y_te))\n",
        "            mae = mean_absolute_error(y_te, predictions)\n",
        "            mae_naive = mean_absolute_error(y_te, [np.mean(y_te)]*len(y_te))\n",
        "\n",
        "            print(f\"Test R^2 score for {target} using split {i}: {score}\")\n",
        "            print(f\"Test MSE for {target} using split {i}: {mse}\")\n",
        "\n",
        "            equations = model.get_best()\n",
        "            best_equation = equations['equation']\n",
        "\n",
        "            # Storing results\n",
        "            results.append({\n",
        "                'split': i,\n",
        "                'target': target,\n",
        "                'R2_score': score,\n",
        "                'MSE': mse,\n",
        "                'MMSE' : mse/mse_naive,\n",
        "                'best_equation': best_equation,\n",
        "                'MAE': mae,\n",
        "                'MASE' : mae/mae_naive,\n",
        "                'features' : best_features\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce09472d-9356-4a0d-afd4-e99c14f566d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce09472d-9356-4a0d-afd4-e99c14f566d7",
        "outputId": "63f8fea8-4eb0-4474-b460-be7f2d18c835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for SP using split 0: -0.3672688112222269\n",
            "Test MSE for SP using split 0: 566.2222035699444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for DP using split 0: -0.18927965952469372\n",
            "Test MSE for DP using split 0: 129.0504493093141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for SP using split 1: 0.014943598229528177\n",
            "Test MSE for SP using split 1: 193.31002960715597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for DP using split 1: -0.12357414799288535\n",
            "Test MSE for DP using split 1: 92.04602344199016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for SP using split 2: -0.05104110024222375\n",
            "Test MSE for SP using split 2: 101.81768759519679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for DP using split 2: -0.03656842269367111\n",
            "Test MSE for DP using split 2: 63.29283343157075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for SP using split 3: -1.0240406414411343\n",
            "Test MSE for SP using split 3: 203.44692954599432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for DP using split 3: -1.488174114348936\n",
            "Test MSE for DP using split 3: 114.17090444885437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for SP using split 4: -0.38604337454462057\n",
            "Test MSE for SP using split 4: 166.49151209710982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1302: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pysr/sr.py:1889: UserWarning: Note: you are running with 10 features or more. Genetic algorithms like used in PySR scale poorly with large numbers of features. You should run PySR for more `niterations` to ensure it can find the correct variables, or, alternatively, do a dimensionality reduction beforehand. For example, `X = PCA(n_components=6).fit_transform(X)`, using scikit-learn's `PCA` class, will reduce the number of features to 6 in an interpretable way, as each resultant feature will be a linear combination of the original features. \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test R^2 score for DP using split 4: -0.06423876782666715\n",
            "Test MSE for DP using split 4: 67.93013230768045\n",
            "   split target  R2_score         MSE      MMSE  \\\n",
            "0      0     SP -0.367269  566.222204  1.367269   \n",
            "1      0     DP -0.189280  129.050449  1.189280   \n",
            "2      1     SP  0.014944  193.310030  0.985056   \n",
            "3      1     DP -0.123574   92.046023  1.123574   \n",
            "4      2     SP -0.051041  101.817688  1.051041   \n",
            "5      2     DP -0.036568   63.292833  1.036568   \n",
            "6      3     SP -1.024041  203.446930  2.024041   \n",
            "7      3     DP -1.488174  114.170904  2.488174   \n",
            "8      4     SP -0.386043  166.491512  1.386043   \n",
            "9      4     DP -0.064239   67.930132  1.064239   \n",
            "\n",
            "                                       best_equation        MAE      MASE  \\\n",
            "0                                     abs(118.28823)  17.277001  1.089003   \n",
            "1                                      abs(-66.2375)   7.814936  0.931302   \n",
            "2  (((T_c_norm * dsdc_16) - T_peak_c) * 210.86816...  10.450998  0.938755   \n",
            "3                                       abs(66.5918)   8.014050  1.114328   \n",
            "4                                     abs(-121.4633)   7.715148  1.033953   \n",
            "5                                      abs(66.91152)   6.376056  0.985405   \n",
            "6                                      abs(122.8344)  11.477797  1.381065   \n",
            "7                                     abs(-68.73211)   8.991573  1.645686   \n",
            "8                                   abs(-122.253136)  10.199196  1.103426   \n",
            "9                                      abs(67.60556)   7.301195  1.032800   \n",
            "\n",
            "                                            features  \n",
            "0  [ppg_a, apg_histogram_down_9, apg_histogram_do...  \n",
            "1  [T_a, ppg_d, apg_histogram_down_5, apg_d, apg_...  \n",
            "2  [T_b_norm, S2_norm, usdc_3, AUCdia, S1_norm, d...  \n",
            "3  [T_a, ppg4_histogram_up_0, ppg3_histogram_up_4...  \n",
            "4  [T_e, SW25, TNegSteepest, ppg_b, ppg_e, DWdivS...  \n",
            "5  [T_b, dsdc_15, dsdc_16, T_d_norm, T_peak_b, ds...  \n",
            "6  [ratio_apg_d, ppg4_histogram_up_1, Steepest, a...  \n",
            "7  [ratio_ppg_e, usdc_3, ppg3_histogram_down_0, T...  \n",
            "8  [ppg_d, TNegSteepest_norm, DWdivSW50, SQI_kurt...  \n",
            "9  [T_c, TNegSteepest_norm, DW50, T_b, ratio_ppg_...  \n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    folds = load_datasets()\n",
        "    splits = split_datasets(folds)\n",
        "    results = perform_symbolic_regression(splits, pysr_settings)\n",
        "\n",
        "    # Convert results to DataFrame for easier analysis and export\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f88678-f2f3-4234-80e3-30aefb0edff9",
      "metadata": {
        "id": "25f88678-f2f3-4234-80e3-30aefb0edff9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}